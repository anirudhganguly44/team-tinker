epoch, learning rate, training loss, training error, test loss, test error

1, 0.1, 4.800272583961487, 0.890625, 2.409518241882324, 0.8900000005960464
2, 0.1, 4.613539814949036, 0.833984375, 2.257812738418579, 0.8299999982118607
3, 0.1, 4.494998216629028, 0.779296875, 2.207468032836914, 0.7999999970197678
4, 0.1, 4.205015420913696, 0.58203125, 2.4386990070343018, 0.7800000011920929
5, 0.1, 3.960944175720215, 0.412109375, 3.029212713241577, 0.760000005364418
6, 0.1, 3.5722354650497437, 0.3125, 3.897155523300171, 0.7800000011920929
7, 0.1, 3.135155498981476, 0.21484375, 5.455854415893555, 0.8499999940395355
8, 0.1, 2.9677436351776123, 0.1640625, 6.025117874145508, 0.8400000035762787
9, 0.1, 2.885630965232849, 0.119140625, 6.379769325256348, 0.8199999928474426
10, 0.1, 2.791281282901764, 0.095703125, 7.702268123626709, 0.8199999928474426
1, 0.1, 4.030979633331299, 0.54296875, 4.103734016418457, 0.880000002682209
2, 0.1, 3.5761176347732544, 0.40625, 4.9240617752075195, 0.8400000035762787
3, 0.1, 3.3781444430351257, 0.29296875, 6.383460521697998, 0.8299999982118607
4, 0.1, 3.063417613506317, 0.21484375, 9.073880195617676, 0.8499999940395355
5, 0.1, 2.9176406860351562, 0.162109375, 9.604180335998535, 0.8599999994039536
6, 0.1, 2.7926443815231323, 0.119140625, 10.12355899810791, 0.8999999985098839
7, 0.1, 2.7001850605010986, 0.08984375, 9.452311515808105, 0.8700000047683716
8, 0.1, 2.6084171533584595, 0.048828125, 9.916828155517578, 0.8499999940395355
9, 0.1, 2.5736201405525208, 0.0390625, 9.707830429077148, 0.8499999940395355
10, 0.1, 2.534930169582367, 0.04296875, 10.119854927062988, 0.8100000023841858
