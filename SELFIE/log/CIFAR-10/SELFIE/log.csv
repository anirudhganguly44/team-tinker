epoch, learning rate, training loss, training error, test loss, test error

1, 0.1, 4.743203401565552, 0.853515625, 2.382420539855957, 0.7800000011920929
2, 0.1, 4.504104971885681, 0.779296875, 2.2491369247436523, 0.8299999982118607
3, 0.1, 4.410404562950134, 0.75, 2.084038734436035, 0.7900000065565109
4, 0.1, 3.8707618713378906, 0.48046875, 2.1217451095581055, 0.8499999940395355
5, 0.1, 3.564188778400421, 0.359375, 2.402837038040161, 0.8900000005960464
6, 0.1, 3.2727103233337402, 0.25390625, 2.486884593963623, 0.8700000047683716
7, 0.1, 2.869022488594055, 0.138671875, 2.706902503967285, 0.8499999940395355
8, 0.1, 2.748180866241455, 0.10546875, 3.249990463256836, 0.8100000023841858
9, 0.1, 2.599368929862976, 0.064453125, 4.050479888916016, 0.8299999982118607
10, 0.1, 2.513098955154419, 0.041015625, 4.8534440994262695, 0.8400000035762787
1, 0.1, 3.6614322662353516, 0.37109375, 10.51894760131836, 0.9400000013411045
2, 0.1, 3.0667994022369385, 0.1796875, 8.035181999206543, 0.9299999997019768
3, 0.1, 2.799627900123596, 0.1015625, 5.572795391082764, 0.8999999985098839
4, 0.1, 2.782110333442688, 0.080078125, 5.1746344566345215, 0.880000002682209
5, 0.1, 2.6249196529388428, 0.052734375, 5.339868545532227, 0.8700000047683716
6, 0.1, 2.5054615139961243, 0.0234375, 5.965658187866211, 0.8599999994039536
7, 0.1, 2.4835970997810364, 0.01953125, 6.291756629943848, 0.8499999940395355
8, 0.1, 2.441986083984375, 0.0234375, 6.459012985229492, 0.8499999940395355
9, 0.1, 2.420670509338379, 0.009765625, 7.014068126678467, 0.8499999940395355
10, 0.1, 2.4155009984970093, 0.0234375, 7.259890556335449, 0.8499999940395355
