epoch, learning rate, training loss, training error, test loss, test error

1, 0.1, 4.742090106010437, 0.87109375, 2.338003396987915, 0.8499999940395355
2, 0.1, 4.596038818359375, 0.787109375, 2.2900736331939697, 0.9099999964237213
3, 0.1, 4.502394318580627, 0.79296875, 2.233006715774536, 0.9200000017881393
4, 0.1, 4.203062415122986, 0.5703125, 2.2843356132507324, 0.8100000023841858
5, 0.1, 4.024262011051178, 0.431640625, 2.7850143909454346, 0.8400000035762787
6, 0.1, 3.4524723887443542, 0.236328125, 3.9504384994506836, 0.7900000065565109
7, 0.1, 2.9723212718963623, 0.126953125, 4.249861240386963, 0.7699999958276749
8, 0.1, 2.7791653871536255, 0.080078125, 4.896924018859863, 0.7400000095367432
9, 0.1, 2.582191586494446, 0.044921875, 5.947537422180176, 0.760000005364418
10, 0.1, 2.494658589363098, 0.02734375, 6.618399143218994, 0.75
1, 0.1, 3.579278588294983, 0.388671875, 8.473193168640137, 0.8900000005960464
2, 0.1, 3.025244414806366, 0.16015625, 6.554952621459961, 0.8400000035762787
3, 0.1, 2.865165412425995, 0.134765625, 7.066032886505127, 0.7900000065565109
4, 0.1, 2.8157857060432434, 0.091796875, 7.7855143547058105, 0.7900000065565109
5, 0.1, 2.702772855758667, 0.056640625, 7.038695812225342, 0.760000005364418
6, 0.1, 2.5871734619140625, 0.0390625, 6.5137200355529785, 0.75
7, 0.1, 2.5143773555755615, 0.03125, 6.2858710289001465, 0.75
8, 0.1, 2.4674811959266663, 0.0234375, 6.548241138458252, 0.7400000095367432
9, 0.1, 2.4486040472984314, 0.025390625, 6.765566825866699, 0.7400000095367432
10, 0.1, 2.3996591567993164, 0.0078125, 7.6256422996521, 0.75
